LEARNING_RATE,EPOCHS,BATCH_SIZE,DROPOUT_RATE,IS_L2_REGULARIZATION,L2_REGULARIZATION_RATE,HUBER_DELTA,layers_info
0.0001,100,64,0.3,False,0.0,1.5,"Layer 1: dense (Dense) - Input shape: None, Output shape: None, Activation: relu
Layer 2: batch_normalization (BatchNormalization) - Input shape: None, Output shape: None, Activation: None
Layer 3: dropout (Dropout) - Input shape: None, Output shape: None, Activation: None
Layer 4: dense_1 (Dense) - Input shape: None, Output shape: None, Activation: relu
Layer 5: batch_normalization_1 (BatchNormalization) - Input shape: None, Output shape: None, Activation: None
Layer 6: dropout_1 (Dropout) - Input shape: None, Output shape: None, Activation: None
Layer 7: dense_2 (Dense) - Input shape: None, Output shape: None, Activation: relu
Layer 8: dense_3 (Dense) - Input shape: None, Output shape: None, Activation: relu
Layer 9: dense_4 (Dense) - Input shape: None, Output shape: None, Activation: linear"
0.0001,100,64,0.3,False,0.0,1.5,"Layer 1: dense (Dense) - Input shape: None, Output shape: None, Activation: relu
Layer 2: batch_normalization (BatchNormalization) - Input shape: None, Output shape: None, Activation: None
Layer 3: dropout (Dropout) - Input shape: None, Output shape: None, Activation: None
Layer 4: dense_1 (Dense) - Input shape: None, Output shape: None, Activation: relu
Layer 5: batch_normalization_1 (BatchNormalization) - Input shape: None, Output shape: None, Activation: None
Layer 6: dropout_1 (Dropout) - Input shape: None, Output shape: None, Activation: None
Layer 7: dense_2 (Dense) - Input shape: None, Output shape: None, Activation: relu
Layer 8: dense_3 (Dense) - Input shape: None, Output shape: None, Activation: linear"
